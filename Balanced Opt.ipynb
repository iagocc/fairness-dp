{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import pyemd\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from scipy.stats import wasserstein_distance\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(9001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Datasets\n",
    "Two datasets of 500 and 7300 samples\n",
    "Each person in the datasets has 6 protected attributes:\n",
    "* Gender                  = {Male, Female}\n",
    "* Country                 = {America, India, Other}\n",
    "* Year of Birth           = [1950, 2009]\n",
    "* Language                = {English, Indian, Other}\n",
    "* Ethnicity               = {White, African-American, Indian, Other}\n",
    "* Years of Experience     = [0,30]\n",
    "\n",
    "And two observed attributes:\n",
    "* Language Test = [25,100]\n",
    "* Approval rate = [25,100]\n",
    "\n",
    "Task Qualification Function:\n",
    "\n",
    "$f = \\alpha b_1 + (1-\\alpha)b_2$\n",
    "\n",
    "Where $b_1$ is the *language test* and $b_2$ is *approval rate* and the $\\alpha \\in \\{0,0.3,0.5,0.7,1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the protected columns\n",
    "protected_attrs = {\n",
    "    'gender' : ['male', 'female'],\n",
    "    'country' : ['america', 'india', 'other'],\n",
    "    'year_birth' : list(range(1950, 2009+1)),\n",
    "    'language' : ['english', 'india', 'other'],\n",
    "    'ethnicity' : ['white', 'african-american', 'indian', 'other'],\n",
    "    'year_experience' : list(range(0,30+1))\n",
    "}\n",
    "# the observed columns\n",
    "observed_attrs = {\n",
    "    'language_test' : list(range(25,100+1)),\n",
    "    'approval_rate' : list(range(25,100+1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n):\n",
    "    '''Generates the dataset accordinly the parameter n that represents the amount of people'''\n",
    "    # define the dataset structure\n",
    "    dataset = []\n",
    "    # generate the samples\n",
    "    for i in range(n):\n",
    "        sample_protected = [v[random.randint(0,len(v)-1)] for k,v in protected_attrs.items()]\n",
    "        sample_observed  = [v[random.randint(0,len(v)-1)] for k,v in observed_attrs.items()]\n",
    "        sample = sample_protected + sample_observed\n",
    "        dataset.append(sample)\n",
    "        \n",
    "    columns = list(protected_attrs.keys()) + list(observed_attrs.keys())\n",
    "    return pd.DataFrame(dataset, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = generate_dataset(500)\n",
    "big_dataset = generate_dataset(7300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAlgorithm:\n",
    "    def __init__(self, attributes, bins=list(range(25,100+1))):\n",
    "        self.attributes = attributes.copy()\n",
    "        self.bins = bins\n",
    "        \n",
    "    def worst_attribute(self,W,f,A):\n",
    "        worst_attr = ''\n",
    "        highest_emd = float('-inf')\n",
    "        \n",
    "        for column, possible_values in A.items():\n",
    "            histograms = []\n",
    "            for value in possible_values:\n",
    "                query_string = '{} == \"{}\"'.format(column, value)\n",
    "                partition = W.query(query_string) # query by attribute value\n",
    "                \n",
    "                if partition.empty:\n",
    "                    continue\n",
    "                \n",
    "                h,b = np.histogram([f(row) for i,row in partition.iterrows()], bins=self.bins)\n",
    "                histograms.append(h)\n",
    "            \n",
    "            # we need more than 1 attr-value to compare the histograms\n",
    "            if len(histograms) <= 1:\n",
    "                return ''\n",
    "            # we need to make the pairwise EMD\n",
    "            pairs = combinations(histograms, 2)\n",
    "            emd_list = []\n",
    "            for pair in pairs:\n",
    "                emd_value = wasserstein_distance(pair[0], pair[1])\n",
    "                emd_list.append(emd_value)\n",
    "                \n",
    "            avg_emd = np.mean(emd_list)\n",
    "            if avg_emd > highest_emd:\n",
    "                highest_emd = avg_emd\n",
    "                worst_attr = column\n",
    "            \n",
    "        return worst_attr, highest_emd\n",
    "        \n",
    "    def split(self,W,a):\n",
    "        if type(W) is list:\n",
    "            array = []\n",
    "            for w in W:\n",
    "                array += [df for _, df in w.groupby(a)]\n",
    "            return array\n",
    "                \n",
    "        return [df for _, df in W.groupby(a)]\n",
    "\n",
    "    def average_emd(self,W,f):\n",
    "        histograms = []\n",
    "        emd_list = []\n",
    "        for partition in W:\n",
    "            h,b = np.histogram([f(row) for i,row in partition.iterrows()], bins=self.bins)\n",
    "            histograms.append(h)\n",
    "\n",
    "        if len(histograms) <= 1:\n",
    "            return 0\n",
    "        pairs = combinations(histograms, 2)\n",
    "        for pair in pairs:\n",
    "            emd_value = wasserstein_distance(pair[0], pair[1])\n",
    "            emd_list.append(emd_value)\n",
    "\n",
    "        return np.mean(emd_list)\n",
    "\n",
    "    def run(self,W,f,A):\n",
    "        removal_list = []\n",
    "        A = A.copy()\n",
    "        a, emd_val = self.worst_attribute(W,f,A)\n",
    "        removal_list.append(a)\n",
    "        A.pop(a) # line 2 of the pseudo code\n",
    "        current = self.split(W,a)\n",
    "        current_avg = self.average_emd(current,f)\n",
    "\n",
    "        while len(A) > 0:\n",
    "            worst = [self.worst_attribute(c,f,A) for c in current]\n",
    "            max_index = np.argmax([t[1] for t in worst])\n",
    "            a = worst[max_index][0]\n",
    "            \n",
    "            removal_list.append(a)\n",
    "            A.pop(a)\n",
    "            children = self.split(current[max_index],a)\n",
    "            \n",
    "            # add the others partitions not splitted\n",
    "            for i, partition in enumerate(current):\n",
    "                if i == max_index:\n",
    "                    continue\n",
    "                children += [current[i]]\n",
    "            \n",
    "            children_avg = self.average_emd(children,f)\n",
    "            if current_avg >= children_avg:\n",
    "                break\n",
    "            else:\n",
    "                current = children\n",
    "                current_avg = children_avg\n",
    "\n",
    "        return current, current_avg, removal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringFunction:\n",
    "    def __init__(self, alpha, b1_name, b2_name):\n",
    "        self.a = alpha\n",
    "        self.b1_name = b1_name\n",
    "        self.b2_name = b2_name\n",
    "        \n",
    "    def f(self,row):\n",
    "        b1 = row[self.b1_name]\n",
    "        b2 = row[self.b1_name]\n",
    "        return (self.a*b1 + (1-self.a)*b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0,0.3,0.5,0.7,1]\n",
    "\n",
    "f3 = ScoringFunction(alpha[2], 'language_test', 'approval_rate').f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "balanced = BalancedAlgorithm(protected_attrs)\n",
    "result = balanced.run(small_dataset.copy(), f3, protected_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final EMD Value = 1.0336507936507935\n",
      "Splitted on: ['gender', 'country', 'ethnicity', 'language']\n"
     ]
    }
   ],
   "source": [
    "print('Final EMD Value = {}\\nSplitted on: {}'.format(result[1],result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
