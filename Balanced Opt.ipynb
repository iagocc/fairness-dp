{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Datasets\n",
    "Two datasets of 500 and 7300 samples\n",
    "Each person in the datasets has 6 protected attributes:\n",
    "* Gender                  = {Male, Female}\n",
    "* Country                 = {America, India, Other}\n",
    "* Year of Birth           = [1950, 2009]\n",
    "* Language                = {English, Indian, Other}\n",
    "* Ethnicity               = {White, African-American, Indian, Other}\n",
    "* Years of Experience     = [0,30]\n",
    "\n",
    "And two observed attributes:\n",
    "* Language Test = [25,100]\n",
    "* Approval rate = [25,100]\n",
    "\n",
    "Task Qualification Function:\n",
    "\n",
    "$f = \\alpha b_1 + (1-\\alpha)b_2$\n",
    "\n",
    "Where $b_1$ is the *language test* and $b_2$ is *approval rate* and the $\\alpha \\in \\{0,0.3,0.5,0.7,1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the protected columns\n",
    "protected_attrs = {\n",
    "    'gender' : ['male', 'female'],\n",
    "    'country' : ['america', 'india', 'other'],\n",
    "    'year_birth' : (1950, 2009),\n",
    "    'language' : ['english', 'india', 'other'],\n",
    "    'ethnicity' : ['white', 'african-american', 'indian', 'other'],\n",
    "    'year_experience' : (0,30)\n",
    "}\n",
    "# the observed columns\n",
    "observed_attrs = {\n",
    "    'language_test' : (25,100),\n",
    "    'approval_rate' : (25,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n):\n",
    "    '''Generates the dataset accordinly the parameter n that represents the amount of people'''\n",
    "    # define the dataset structure\n",
    "    dataset = []\n",
    "    # generate the samples\n",
    "    for i in range(n):\n",
    "        sample_protected = [v[random.randint(0,len(v)-1)] if type(v) is list else random.randint(v[0], v[1]) for k,v in protected_attrs.items()]\n",
    "        sample_observed  = [random.randint(v[0], v[1]) for k,v in observed_attrs.items()]\n",
    "        sample = sample_protected + sample_observed\n",
    "        dataset.append(sample)\n",
    "        \n",
    "    columns = list(protected_attrs.keys()) + list(observed_attrs.keys())\n",
    "    return pd.DataFrame(dataset, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = generate_dataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>year_birth</th>\n",
       "      <th>language</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>year_experience</th>\n",
       "      <th>language_test</th>\n",
       "      <th>approval_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1953</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1973</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>19</td>\n",
       "      <td>87</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1987</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>2007</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>2007</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1991</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1958</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1973</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>2005</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1966</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2008</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1977</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>2008</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>18</td>\n",
       "      <td>97</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>2001</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1994</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1963</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>2006</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1983</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1993</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1953</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>16</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2007</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2007</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2007</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1956</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>23</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1957</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1963</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1974</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1985</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1994</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>2008</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>29</td>\n",
       "      <td>91</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1997</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1958</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1983</td>\n",
       "      <td>other</td>\n",
       "      <td>african-american</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1953</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>17</td>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1980</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1978</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>30</td>\n",
       "      <td>71</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1951</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1960</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2009</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1972</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>22</td>\n",
       "      <td>97</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1987</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1977</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1999</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1966</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>2006</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1968</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1976</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1970</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>2006</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>8</td>\n",
       "      <td>94</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1987</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1992</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2006</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1958</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1981</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1968</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1961</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1984</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1990</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1992</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1994</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  country  year_birth language         ethnicity  year_experience  \\\n",
       "0      male    india        1953    india             white               13   \n",
       "1      male    india        1973    india            indian               19   \n",
       "2    female    india        1987    other             other                1   \n",
       "3      male  america        2007    other            indian               23   \n",
       "4    female    other        2007    india  african-american               21   \n",
       "5    female    other        1991    india  african-american               11   \n",
       "6    female    other        1958  english            indian               30   \n",
       "7    female    india        1973    other            indian                7   \n",
       "8      male  america        2005    india             other               21   \n",
       "9    female  america        1966    india  african-american                5   \n",
       "10   female    india        2008    other             other               23   \n",
       "11     male    india        1977    other            indian                9   \n",
       "12   female    other        2008  english             white               18   \n",
       "13     male    other        2001    other             other               19   \n",
       "14     male  america        1994    other             white                7   \n",
       "15   female    india        1963  english            indian                1   \n",
       "16     male    india        2006  english             white               15   \n",
       "17     male    other        1983  english  african-american                8   \n",
       "18   female    india        1993  english            indian               15   \n",
       "19     male  america        1953    other            indian               16   \n",
       "20   female    india        2007  english  african-american               22   \n",
       "21   female    india        2007    india            indian               23   \n",
       "22   female    india        2007    india             other               30   \n",
       "23     male    other        1956    india            indian               23   \n",
       "24     male    other        1957  english            indian               12   \n",
       "25     male    india        1963    other             other               21   \n",
       "26     male  america        1974    india             white                3   \n",
       "27     male    other        1985    india             other               10   \n",
       "28     male  america        1994    other             white                4   \n",
       "29     male  america        2008    india            indian               29   \n",
       "..      ...      ...         ...      ...               ...              ...   \n",
       "470  female  america        1997    india             other                5   \n",
       "471    male    india        1958  english             other               22   \n",
       "472    male    india        1983    other  african-american                4   \n",
       "473  female  america        1953  english  african-american               17   \n",
       "474  female    india        1980    india             white                8   \n",
       "475    male    india        1978    india             white               30   \n",
       "476  female  america        1951  english            indian                6   \n",
       "477    male    other        1960    india            indian               17   \n",
       "478  female    india        2009  english  african-american                1   \n",
       "479  female    other        1972  english             white               22   \n",
       "480  female    india        1987  english             other               19   \n",
       "481  female  america        1977    india             other               23   \n",
       "482  female    india        1999    india             white               24   \n",
       "483    male  america        1966    other            indian               25   \n",
       "484    male  america        2006    india             other                9   \n",
       "485  female    india        1968    india             other               22   \n",
       "486  female    india        1976  english             other               21   \n",
       "487    male    other        1970  english             white                8   \n",
       "488    male    other        2006  english             white                8   \n",
       "489    male    india        1987  english             white                2   \n",
       "490  female    india        1992    india  african-american               12   \n",
       "491  female    india        2006  english             other               17   \n",
       "492    male    india        1958    other            indian               24   \n",
       "493  female    india        1981    other            indian               25   \n",
       "494  female  america        1968  english             white               27   \n",
       "495    male    india        1961    india            indian               20   \n",
       "496    male  america        1984    india             white               14   \n",
       "497    male    other        1990    india             other                3   \n",
       "498    male  america        1992    india  african-american               21   \n",
       "499  female    india        1994  english             other               24   \n",
       "\n",
       "     language_test  approval_rate  \n",
       "0               51             60  \n",
       "1               87             63  \n",
       "2               99             30  \n",
       "3               29             49  \n",
       "4               27             53  \n",
       "5               46             92  \n",
       "6               75             53  \n",
       "7               45             29  \n",
       "8               82             45  \n",
       "9               38             42  \n",
       "10              55             62  \n",
       "11              30             97  \n",
       "12              97             34  \n",
       "13              31             42  \n",
       "14              81             29  \n",
       "15              37             45  \n",
       "16              76             65  \n",
       "17              27             35  \n",
       "18              86             86  \n",
       "19              61             85  \n",
       "20              47             29  \n",
       "21              35             44  \n",
       "22              47             88  \n",
       "23              88             50  \n",
       "24              40             41  \n",
       "25              28             96  \n",
       "26              47             40  \n",
       "27              46             95  \n",
       "28              28             94  \n",
       "29              91             33  \n",
       "..             ...            ...  \n",
       "470             89             76  \n",
       "471             80             93  \n",
       "472             90             81  \n",
       "473             94             72  \n",
       "474             38             92  \n",
       "475             71             54  \n",
       "476             26             53  \n",
       "477             58             34  \n",
       "478             79             57  \n",
       "479             97             28  \n",
       "480             60             28  \n",
       "481             53             46  \n",
       "482             96             88  \n",
       "483             94             73  \n",
       "484             77             34  \n",
       "485             33             43  \n",
       "486             36             25  \n",
       "487             27             93  \n",
       "488             94             37  \n",
       "489             71             58  \n",
       "490             32             74  \n",
       "491             83             73  \n",
       "492             42             64  \n",
       "493             41             95  \n",
       "494             50             31  \n",
       "495             33             99  \n",
       "496             97             25  \n",
       "497             74             41  \n",
       "498             68             57  \n",
       "499             50             58  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(small_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAlgorithm:\n",
    "    def __init__(self, attributes, bins=np.arange(0,1.1,0.1)):\n",
    "        self.attributes = attributes.copy()\n",
    "        self.bins = bins\n",
    "        self.dist = cv2.DIST_L2\n",
    "        \n",
    "    def generate_signature(self, h, b):\n",
    "        ''''\n",
    "        Convert numpy histogram in signature data structure necessary for the usage of OpenCV EMD\n",
    "        Create a matrix that each row is a frequency value obtained by the histogram algorithm and the bin value (position)\n",
    "        '''\n",
    "        return np.array([(n, i) for i,n in enumerate(h)]).astype(np.float32)\n",
    "    \n",
    "    def emd_pairwise(self, histograms):\n",
    "        pairs = combinations(histograms, 2)\n",
    "        emd_list = []\n",
    "        for pair in pairs:\n",
    "            emd_value, _, flow = cv2.EMD(pair[0], pair[1], self.dist)\n",
    "            emd_list.append(emd_value/np.sum(flow))\n",
    "            \n",
    "        return emd_list\n",
    "    \n",
    "    def generate_histogram(self, f, partition):\n",
    "        samples = [f(row) for _,row in partition.iterrows()]\n",
    "        h,b = np.histogram(samples, bins=self.bins, density=True)\n",
    "        return self.generate_signature(h,b)\n",
    "        \n",
    "    def worst_attribute(self,dataset,f,A):\n",
    "        worst_attr = ''\n",
    "        highest_emd = float('-inf')\n",
    "        splittable = None\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            raise ValueError(\"The dataset can not be empty\")\n",
    "        \n",
    "        for W in dataset:\n",
    "            for column, possible_values in A.items():\n",
    "                \n",
    "                if type(possible_values) is not list:\n",
    "                    possible_values = list(range(possible_values[0], possible_values[1]+1))\n",
    "                \n",
    "                histograms = []\n",
    "                for value in possible_values:\n",
    "                    query_string = '{} == \"{}\"'.format(column, value)\n",
    "                    partition = W.query(query_string) # query by attribute value\n",
    "                    \n",
    "                    if partition.empty:\n",
    "                        continue\n",
    "\n",
    "                    histograms.append(self.generate_histogram(f, partition))\n",
    "\n",
    "                # we need more than 1 attr-value to compare the histograms\n",
    "                if len(histograms) <= 1:\n",
    "                    continue\n",
    "                \n",
    "                # we need to make the pairwise EMD\n",
    "                emd_list = self.emd_pairwise(histograms)\n",
    "\n",
    "                avg_emd = np.average(emd_list)\n",
    "                if avg_emd > highest_emd:\n",
    "                    highest_emd = avg_emd\n",
    "                    worst_attr = column\n",
    "                    splittable = W\n",
    "        \n",
    "        assert(worst_attr is not '' and highest_emd is not float('-inf'))\n",
    "        \n",
    "        return worst_attr, highest_emd, splittable\n",
    "        \n",
    "    def split(self,W,a):\n",
    "        if type(W) is list:\n",
    "            array = []\n",
    "            for w in W:\n",
    "                array += [df for _, df in w.groupby(a)]\n",
    "            return array\n",
    "                \n",
    "        return [df for _, df in W.groupby(a)]\n",
    "\n",
    "    def average_emd(self,W,f):\n",
    "        histograms = []\n",
    "        emd_list = []\n",
    "        for partition in W:\n",
    "            histograms.append(self.generate_histogram(f, partition))\n",
    "\n",
    "        if len(histograms) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        emd_list = self.emd_pairwise(histograms)\n",
    "        return np.average(emd_list)\n",
    "\n",
    "    def run(self,W,f,attr):\n",
    "        removal_list = []\n",
    "        avg_list = []\n",
    "        A = attr.copy()\n",
    "        \n",
    "        a, emd_val, splittable = self.worst_attribute([W],f,A)\n",
    "        \n",
    "        removal_list.append(a)\n",
    "        A.pop(a) # line 2 of the pseudo code\n",
    "        \n",
    "        current = self.split(splittable, a)\n",
    "        current_avg = self.average_emd(current, f)\n",
    "        avg_list.append(current_avg)\n",
    "\n",
    "        while len(A) > 0:\n",
    "            try:\n",
    "                worst = self.worst_attribute(current,f,A)\n",
    "            except:\n",
    "                print(\"There is no possible to get the worst attribute with the current variable.\")\n",
    "                print(\"Current has a lenght of {}\".format(len(current)))\n",
    "                for c in current:\n",
    "                    display(c)\n",
    "            \n",
    "            a = worst[0]\n",
    "            A.pop(a)\n",
    "            children = self.split(worst[2],a)\n",
    "            \n",
    "            # add the others partitions not splitted\n",
    "            for partition in current:\n",
    "                if partition.equals(worst[2]):\n",
    "                    continue\n",
    "                children += [partition]\n",
    "            \n",
    "            children_avg = self.average_emd(children,f)\n",
    "            if current_avg >= children_avg:\n",
    "                break\n",
    "            else:\n",
    "                current = children\n",
    "                current_avg = children_avg\n",
    "                \n",
    "                avg_list.append(current_avg)\n",
    "                removal_list.append(a)\n",
    "\n",
    "        return current, np.mean(avg_list), removal_list, avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringFunction:\n",
    "    def __init__(self, alpha=0, b1_name='', b2_name=''):\n",
    "        self.a = alpha\n",
    "        self.b1_name = b1_name\n",
    "        self.b2_name = b2_name\n",
    "        \n",
    "    def f(self,row):\n",
    "        b1 = row[self.b1_name]\n",
    "        b2 = row[self.b2_name]\n",
    "        return (self.a*b1 + (1-self.a)*b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0,0.3,0.5,0.7,1.0]\n",
    "\n",
    "f1 = ScoringFunction(alpha=alpha[1], b1_name='language_test', b2_name='approval_rate').f\n",
    "f2 = ScoringFunction(alpha=alpha[2], b1_name='language_test', b2_name='approval_rate').f\n",
    "f3 = ScoringFunction(alpha=alpha[3], b1_name='language_test', b2_name='approval_rate').f\n",
    "f4 = ScoringFunction(alpha=alpha[4], b1_name='language_test', b2_name='approval_rate').f\n",
    "f5 = ScoringFunction(alpha=alpha[0], b1_name='language_test', b2_name='approval_rate').f\n",
    "\n",
    "f6 = lambda row: random.uniform(.8, 1) if row['gender'] == 'male' else random.uniform(0, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e010700bd84ef788bb4d90011223d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r1 = []\n",
    "r2 = []\n",
    "r3 = []\n",
    "r4 = []\n",
    "r5 = []\n",
    "r6 = []\n",
    "for i in tqdm(range(5)):\n",
    "    balanced = BalancedAlgorithm(protected_attrs, bins=np.arange(25,101))\n",
    "    balanced2 = BalancedAlgorithm(protected_attrs)\n",
    "    \n",
    "    result1 = balanced.run(small_dataset.copy(), f1, protected_attrs)\n",
    "    result2 = balanced.run(small_dataset.copy(), f2, protected_attrs)\n",
    "    result3 = balanced.run(small_dataset.copy(), f3, protected_attrs)\n",
    "    result4 = balanced.run(small_dataset.copy(), f4, protected_attrs)\n",
    "    result5 = balanced.run(small_dataset.copy(), f5, protected_attrs)\n",
    "    result6 = balanced2.run(small_dataset.copy(), f6, protected_attrs)\n",
    "    \n",
    "    small_dataset = generate_dataset(500)\n",
    "    \n",
    "    r1.append(result1[1])\n",
    "    r2.append(result2[1])\n",
    "    r3.append(result3[1])\n",
    "    r4.append(result4[1])\n",
    "    r5.append(result5[1])\n",
    "    r6.append(result6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Average EMD = 11.959967871991244\n",
      "F2 Average EMD = 11.271772642151092\n",
      "F3 Average EMD = 11.762982078213623\n",
      "F4 Average EMD = 14.933244916518593\n",
      "F5 Average EMD = 14.69911977549286\n",
      "F6 Average EMD = 0.802485303878784\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Average EMD = {}\".format(np.average(r1)))\n",
    "print(\"F2 Average EMD = {}\".format(np.average(r2)))\n",
    "print(\"F3 Average EMD = {}\".format(np.average(r3)))\n",
    "print(\"F4 Average EMD = {}\".format(np.average(r4)))\n",
    "print(\"F5 Average EMD = {}\".format(np.average(r5)))\n",
    "print(\"F6 Average EMD = {}\".format(np.average(r6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
