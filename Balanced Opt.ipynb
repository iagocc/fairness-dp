{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pyemd\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from IPython.display import display\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Datasets\n",
    "Two datasets of 500 and 7300 samples\n",
    "Each person in the datasets has 6 protected attributes:\n",
    "* Gender                  = {Male, Female}\n",
    "* Country                 = {America, India, Other}\n",
    "* Year of Birth           = [1950, 2009]\n",
    "* Language                = {English, Indian, Other}\n",
    "* Ethnicity               = {White, African-American, Indian, Other}\n",
    "* Years of Experience     = [0,30]\n",
    "\n",
    "And two observed attributes:\n",
    "* Language Test = [25,100]\n",
    "* Approval rate = [25,100]\n",
    "\n",
    "Task Qualification Function:\n",
    "\n",
    "$f = \\alpha b_1 + (1-\\alpha)b_2$\n",
    "\n",
    "Where $b_1$ is the *language test* and $b_2$ is *approval rate* and the $\\alpha \\in \\{0,0.3,0.5,0.7,1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the protected columns\n",
    "protected_attrs = {\n",
    "    'gender' : ['male', 'female'],\n",
    "    'country' : ['america', 'india', 'other'],\n",
    "    'year_birth' : (1950, 2009),\n",
    "    'language' : ['english', 'india', 'other'],\n",
    "    'ethnicity' : ['white', 'african-american', 'indian', 'other'],\n",
    "    'year_experience' : (0,30)\n",
    "}\n",
    "# the observed columns\n",
    "observed_attrs = {\n",
    "    'language_test' : (25,100),\n",
    "    'approval_rate' : (25,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n):\n",
    "    '''Generates the dataset accordinly the parameter n that represents the amount of people'''\n",
    "    # define the dataset structure\n",
    "    dataset = []\n",
    "    # generate the samples\n",
    "    for i in range(n):\n",
    "        sample_protected = [v[random.randint(0,len(v)-1)] if type(v) is list else random.randint(v[0], v[1]) for k,v in protected_attrs.items()]\n",
    "        sample_observed  = [random.randint(v[0], v[1]) for k,v in observed_attrs.items()]\n",
    "        sample = sample_protected + sample_observed\n",
    "        dataset.append(sample)\n",
    "        \n",
    "    columns = list(protected_attrs.keys()) + list(observed_attrs.keys())\n",
    "    return pd.DataFrame(dataset, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = generate_dataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>year_birth</th>\n",
       "      <th>language</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>year_experience</th>\n",
       "      <th>language_test</th>\n",
       "      <th>approval_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1958</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1993</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1996</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1958</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1995</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1990</td>\n",
       "      <td>other</td>\n",
       "      <td>african-american</td>\n",
       "      <td>15</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1961</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>17</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1999</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1963</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1967</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1963</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>90</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>2000</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>2003</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1961</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1998</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1956</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>2004</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>24</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1963</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1986</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>20</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1950</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1978</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1995</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>2001</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1991</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>2003</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1969</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>2002</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1969</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1965</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>2005</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2002</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1972</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1975</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>2004</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>2001</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>26</td>\n",
       "      <td>98</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1977</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>2006</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1958</td>\n",
       "      <td>other</td>\n",
       "      <td>indian</td>\n",
       "      <td>25</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1999</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1953</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1973</td>\n",
       "      <td>india</td>\n",
       "      <td>indian</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1985</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1987</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>2002</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1959</td>\n",
       "      <td>english</td>\n",
       "      <td>african-american</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1989</td>\n",
       "      <td>english</td>\n",
       "      <td>white</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1980</td>\n",
       "      <td>other</td>\n",
       "      <td>african-american</td>\n",
       "      <td>16</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>2007</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1958</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1962</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1960</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>2009</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1970</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1977</td>\n",
       "      <td>english</td>\n",
       "      <td>other</td>\n",
       "      <td>28</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>male</td>\n",
       "      <td>india</td>\n",
       "      <td>1982</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>female</td>\n",
       "      <td>america</td>\n",
       "      <td>1978</td>\n",
       "      <td>india</td>\n",
       "      <td>white</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>female</td>\n",
       "      <td>india</td>\n",
       "      <td>1957</td>\n",
       "      <td>english</td>\n",
       "      <td>indian</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>1989</td>\n",
       "      <td>india</td>\n",
       "      <td>other</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>1979</td>\n",
       "      <td>india</td>\n",
       "      <td>african-american</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>male</td>\n",
       "      <td>america</td>\n",
       "      <td>1994</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  country  year_birth language         ethnicity  year_experience  \\\n",
       "0    female    india        1958  english             white               23   \n",
       "1      male    india        1993    other             white               26   \n",
       "2    female    india        1996  english             white               20   \n",
       "3    female  america        1958  english             white               10   \n",
       "4    female    other        1995    india            indian                5   \n",
       "5    female    india        1990    other  african-american               15   \n",
       "6    female  america        1961    other             other               17   \n",
       "7      male    other        1999    india             other               13   \n",
       "8    female    other        1963  english             white               14   \n",
       "9      male    india        1967    other             white                1   \n",
       "10     male    other        1963    india             other               23   \n",
       "11     male    other        2000    other            indian               30   \n",
       "12     male    india        2003    other             other                3   \n",
       "13   female  america        1961  english            indian               21   \n",
       "14   female    other        1998    india  african-american                0   \n",
       "15     male  america        1956  english             white                5   \n",
       "16   female  america        2004  english             other               24   \n",
       "17     male    other        1963    other             white               26   \n",
       "18   female  america        1986  english             white               20   \n",
       "19   female    india        1950    other            indian               27   \n",
       "20     male    india        1978    other             white               24   \n",
       "21   female  america        1995    other             white               14   \n",
       "22     male  america        2001    other             other               12   \n",
       "23   female  america        1991    other             other               28   \n",
       "24   female  america        2003    india            indian               27   \n",
       "25   female    other        1969    other             white                0   \n",
       "26   female    other        2002    other             white                8   \n",
       "27   female  america        1969    other             white               29   \n",
       "28     male    india        1965    india            indian               11   \n",
       "29   female  america        2005    india             white                3   \n",
       "..      ...      ...         ...      ...               ...              ...   \n",
       "470  female    india        2002    india  african-american               13   \n",
       "471    male  america        1972  english  african-american                6   \n",
       "472  female    india        1975    india             white                1   \n",
       "473    male    other        2004    india             white               30   \n",
       "474  female    other        2001    other            indian               26   \n",
       "475    male    other        1977    other            indian               11   \n",
       "476    male    india        2006    india             white                7   \n",
       "477    male    other        1958    other            indian               25   \n",
       "478  female  america        1999  english             other               10   \n",
       "479    male    india        1953  english            indian               22   \n",
       "480  female    india        1973    india            indian               11   \n",
       "481    male    other        1985  english             white                5   \n",
       "482    male    other        1987    india  african-american               21   \n",
       "483  female    india        2002    india             white               12   \n",
       "484    male    india        1959  english  african-american               13   \n",
       "485    male    other        1989  english             white               11   \n",
       "486    male  america        1980    other  african-american               16   \n",
       "487  female  america        2007    india  african-american               14   \n",
       "488  female    other        1958    other             white                1   \n",
       "489  female    other        1962  english            indian               29   \n",
       "490    male    other        1960    india  african-american               12   \n",
       "491  female    other        2009  english            indian                3   \n",
       "492    male    india        1970  english             other               13   \n",
       "493    male    india        1977  english             other               28   \n",
       "494    male    india        1982    other             other               11   \n",
       "495  female  america        1978    india             white               21   \n",
       "496  female    india        1957  english            indian               15   \n",
       "497    male    other        1989    india             other               18   \n",
       "498  female    other        1979    india  african-american               13   \n",
       "499    male  america        1994    other             white                4   \n",
       "\n",
       "     language_test  approval_rate  \n",
       "0               96             74  \n",
       "1               29             90  \n",
       "2               83             87  \n",
       "3               63             57  \n",
       "4               70             28  \n",
       "5               85             49  \n",
       "6               89             73  \n",
       "7               33             45  \n",
       "8               82             51  \n",
       "9               65             97  \n",
       "10              90             43  \n",
       "11              50             87  \n",
       "12              88             45  \n",
       "13              32             65  \n",
       "14              55             28  \n",
       "15              82             59  \n",
       "16              84             84  \n",
       "17              35             80  \n",
       "18              82             59  \n",
       "19              40             40  \n",
       "20              75             63  \n",
       "21              82             58  \n",
       "22             100             31  \n",
       "23              89             97  \n",
       "24              63             92  \n",
       "25              85             96  \n",
       "26              90             88  \n",
       "27              57             68  \n",
       "28              80             37  \n",
       "29              27             26  \n",
       "..             ...            ...  \n",
       "470             55             96  \n",
       "471             43             29  \n",
       "472             68             51  \n",
       "473             89             99  \n",
       "474             98             61  \n",
       "475             71             64  \n",
       "476             81             93  \n",
       "477             84             75  \n",
       "478             34             33  \n",
       "479             31             83  \n",
       "480             56             54  \n",
       "481             51             75  \n",
       "482             31             92  \n",
       "483             87             91  \n",
       "484             60             45  \n",
       "485             72             68  \n",
       "486             90             35  \n",
       "487             30             97  \n",
       "488             50             71  \n",
       "489             54             96  \n",
       "490             34             92  \n",
       "491             46             93  \n",
       "492             78             88  \n",
       "493             98             99  \n",
       "494             29             27  \n",
       "495             49             43  \n",
       "496             95             76  \n",
       "497             96             45  \n",
       "498             52             72  \n",
       "499             82             43  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(small_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAlgorithm:\n",
    "    def __init__(self, attributes, bins=np.arange(0,1.1,0.1)):\n",
    "        self.attributes = attributes.copy()\n",
    "        self.bins = bins\n",
    "        self.dist = cv2.DIST_L2\n",
    "        \n",
    "    def generate_signature(self, h, b):\n",
    "        ''''\n",
    "        Convert numpy histogram in signature data structure necessary for the usage of OpenCV EMD\n",
    "        Create a matrix that each row is a frequency value obtained by the histogram algorithm and the bin value (position)\n",
    "        '''\n",
    "        return np.array([(n, i) for i,n in enumerate(h)]).astype(np.float32)\n",
    "    \n",
    "    def generate_distance_matrix(self, p1, p2):\n",
    "        return distance_matrix(p1.reshape(len(p1),-1), p2.reshape(len(p1),-1))\n",
    "    \n",
    "    def emd_pairwise(self, histograms):\n",
    "        pairs = combinations(histograms, 2)\n",
    "        emd_list = []\n",
    "        for pair in pairs:\n",
    "            distance = self.generate_distance_matrix(pair[0][1], pair[1][1])\n",
    "            distance = distance / np.max(distance)\n",
    "            emd_value = pyemd.emd(pair[0][0], pair[1][0], distance)\n",
    "            emd_list.append(emd_value)\n",
    "            \n",
    "        return emd_list\n",
    "    \n",
    "    def generate_histogram(self, f, partition):\n",
    "        samples = [f(row) for _,row in partition.iterrows()]\n",
    "        h,b = np.histogram(samples, bins=self.bins)\n",
    "        h = h / np.sum(h) # normalizing\n",
    "        return h,b\n",
    "        \n",
    "    def worst_attribute(self,dataset,f,A):\n",
    "        worst_attr = ''\n",
    "        highest_emd = float('-inf')\n",
    "        splittable = None\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            raise ValueError(\"The dataset can not be empty\")\n",
    "        \n",
    "        for W in dataset:\n",
    "            for column, possible_values in A.items():\n",
    "                \n",
    "                if type(possible_values) is not list:\n",
    "                    possible_values = list(range(possible_values[0], possible_values[1]+1))\n",
    "                \n",
    "                histograms = []\n",
    "                for value in possible_values:\n",
    "                    query_string = '{} == \"{}\"'.format(column, value)\n",
    "                    partition = W.query(query_string) # query by attribute value\n",
    "                    \n",
    "                    if partition.empty:\n",
    "                        continue\n",
    "\n",
    "                    histograms.append(self.generate_histogram(f, partition))\n",
    "\n",
    "                # we need more than 1 attr-value to compare the histograms\n",
    "                if len(histograms) <= 1:\n",
    "                    continue\n",
    "                \n",
    "                # we need to make the pairwise EMD\n",
    "                emd_list = self.emd_pairwise(histograms)\n",
    "\n",
    "                avg_emd = np.average(emd_list)\n",
    "                if avg_emd > highest_emd:\n",
    "                    highest_emd = avg_emd\n",
    "                    worst_attr = column\n",
    "                    splittable = W\n",
    "        \n",
    "        assert(worst_attr is not '' and highest_emd is not float('-inf'))\n",
    "        \n",
    "        return worst_attr, highest_emd, splittable\n",
    "        \n",
    "    def split(self,W,a):\n",
    "        if type(W) is list:\n",
    "            array = []\n",
    "            for w in W:\n",
    "                array += [df for _, df in w.groupby(a)]\n",
    "            return array\n",
    "                \n",
    "        return [df for _, df in W.groupby(a)]\n",
    "\n",
    "    def average_emd(self,W,f):\n",
    "        histograms = []\n",
    "        emd_list = []\n",
    "        for partition in W:\n",
    "            histograms.append(self.generate_histogram(f, partition))\n",
    "\n",
    "        if len(histograms) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        emd_list = self.emd_pairwise(histograms)\n",
    "        return np.average(emd_list)\n",
    "\n",
    "    def run(self,W,f,attr):\n",
    "        removal_list = []\n",
    "        avg_list = []\n",
    "        A = attr.copy()\n",
    "        \n",
    "        a, emd_val, splittable = self.worst_attribute([W],f,A)\n",
    "        \n",
    "        removal_list.append(a)\n",
    "        A.pop(a) # line 2 of the pseudo code\n",
    "        \n",
    "        current = self.split(splittable, a)\n",
    "        current_avg = self.average_emd(current, f)\n",
    "        avg_list.append(current_avg)\n",
    "\n",
    "        while len(A) > 0:\n",
    "            try:\n",
    "                worst = self.worst_attribute(current,f,A)\n",
    "            except:\n",
    "                print(\"There is no possible to get the worst attribute with the current variable.\")\n",
    "                print(\"Current has a lenght of {}\".format(len(current)))\n",
    "                for c in current:\n",
    "                    display(c)\n",
    "            \n",
    "            a = worst[0]\n",
    "            A.pop(a)\n",
    "            children = self.split(worst[2],a)\n",
    "            \n",
    "            # add the others partitions not splitted\n",
    "            for partition in current:\n",
    "                if partition.equals(worst[2]):\n",
    "                    continue\n",
    "                children += [partition]\n",
    "            \n",
    "            children_avg = self.average_emd(children,f)\n",
    "            if current_avg >= children_avg:\n",
    "                break\n",
    "            else:\n",
    "                current = children\n",
    "                current_avg = children_avg\n",
    "                \n",
    "                avg_list.append(current_avg)\n",
    "                removal_list.append(a)\n",
    "\n",
    "        return current, np.mean(avg_list), removal_list, avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringFunction:\n",
    "    def __init__(self, alpha=0, b1_name='', b2_name=''):\n",
    "        self.a = alpha\n",
    "        self.b1_name = b1_name\n",
    "        self.b2_name = b2_name\n",
    "        \n",
    "    def f(self,row):\n",
    "        b1 = row[self.b1_name]\n",
    "        b2 = row[self.b2_name]\n",
    "        return (self.a*b1 + (1-self.a)*b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0,0.3,0.5,0.7,1.0]\n",
    "\n",
    "f1 = ScoringFunction(alpha=alpha[1], b1_name='language_test', b2_name='approval_rate').f\n",
    "f2 = ScoringFunction(alpha=alpha[2], b1_name='language_test', b2_name='approval_rate').f\n",
    "f3 = ScoringFunction(alpha=alpha[3], b1_name='language_test', b2_name='approval_rate').f\n",
    "f4 = ScoringFunction(alpha=alpha[4], b1_name='language_test', b2_name='approval_rate').f\n",
    "f5 = ScoringFunction(alpha=alpha[0], b1_name='language_test', b2_name='approval_rate').f\n",
    "\n",
    "f6 = lambda row: random.uniform(.8, 1) if row['gender'] == 'male' else random.uniform(0, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e60a71400fe424ba94de5fc339eeeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r1 = []\n",
    "r2 = []\n",
    "r3 = []\n",
    "r4 = []\n",
    "r5 = []\n",
    "r6 = []\n",
    "for i in tqdm(range(10)):\n",
    "    balanced = BalancedAlgorithm(protected_attrs, bins=np.arange(25,102))\n",
    "    balanced2 = BalancedAlgorithm(protected_attrs)\n",
    "    \n",
    "    result1 = balanced.run(small_dataset.copy(), f1, protected_attrs)\n",
    "    result2 = balanced.run(small_dataset.copy(), f2, protected_attrs)\n",
    "    result3 = balanced.run(small_dataset.copy(), f3, protected_attrs)\n",
    "    result4 = balanced.run(small_dataset.copy(), f4, protected_attrs)\n",
    "    result5 = balanced.run(small_dataset.copy(), f5, protected_attrs)\n",
    "    result6 = balanced2.run(small_dataset.copy(), f6, protected_attrs)\n",
    "    \n",
    "    small_dataset = generate_dataset(500)\n",
    "    \n",
    "    r1.append(result1[1])\n",
    "    r2.append(result2[1])\n",
    "    r3.append(result3[1])\n",
    "    r4.append(result4[1])\n",
    "    r5.append(result5[1])\n",
    "    r6.append(result6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Average EMD = 0.15788375847645222\n",
      "F2 Average EMD = 0.148685846121797\n",
      "F3 Average EMD = 0.1544794321949134\n",
      "F4 Average EMD = 0.19025563226842085\n",
      "F5 Average EMD = 0.19214884813600971\n",
      "F6 Average EMD = 0.79957418042592\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Average EMD = {}\".format(np.average(r1)))\n",
    "print(\"F2 Average EMD = {}\".format(np.average(r2)))\n",
    "print(\"F3 Average EMD = {}\".format(np.average(r3)))\n",
    "print(\"F4 Average EMD = {}\".format(np.average(r4)))\n",
    "print(\"F5 Average EMD = {}\".format(np.average(r5)))\n",
    "print(\"F6 Average EMD = {}\".format(np.average(r6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
