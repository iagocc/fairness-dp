{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pyemd\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from IPython.display import display\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Datasets\n",
    "Two datasets of 500 and 7300 samples\n",
    "Each person in the datasets has 6 protected attributes:\n",
    "* Gender                  = {Male, Female}\n",
    "* Country                 = {America, India, Other}\n",
    "* Year of Birth           = [1950, 2009]\n",
    "* Language                = {English, Indian, Other}\n",
    "* Ethnicity               = {White, African-American, Indian, Other}\n",
    "* Years of Experience     = [0,30]\n",
    "\n",
    "And two observed attributes:\n",
    "* Language Test = [25,100]\n",
    "* Approval rate = [25,100]\n",
    "\n",
    "Task Qualification Function:\n",
    "\n",
    "$f = \\alpha b_1 + (1-\\alpha)b_2$\n",
    "\n",
    "Where $b_1$ is the *language test* and $b_2$ is *approval rate* and the $\\alpha \\in \\{0,0.3,0.5,0.7,1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the protected columns\n",
    "protected_attrs = {\n",
    "    'gender' : ['male', 'female'],\n",
    "    'country' : ['america', 'india', 'other'],\n",
    "    'year_birth' : (1950, 2009),\n",
    "    'language' : ['english', 'india', 'other'],\n",
    "    'ethnicity' : ['white', 'african-american', 'indian', 'other'],\n",
    "    'year_experience' : (0,30)\n",
    "}\n",
    "# the observed columns\n",
    "observed_attrs = {\n",
    "    'language_test' : (25,100),\n",
    "    'approval_rate' : (25,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n):\n",
    "    '''Generates the dataset accordinly the parameter n that represents the amount of people'''\n",
    "    # define the dataset structure\n",
    "    dataset = []\n",
    "    # generate the samples\n",
    "    for i in range(n):\n",
    "        sample_protected = [v[random.randint(0,len(v)-1)] if type(v) is list else random.randint(v[0], v[1]) for k,v in protected_attrs.items()]\n",
    "        sample_observed  = [random.randint(v[0], v[1]) for k,v in observed_attrs.items()]\n",
    "        sample = sample_protected + sample_observed\n",
    "        dataset.append(sample)\n",
    "        \n",
    "    columns = list(protected_attrs.keys()) + list(observed_attrs.keys())\n",
    "    return pd.DataFrame(dataset, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = generate_dataset(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAlgorithm:\n",
    "    def __init__(self, attributes, bins=np.arange(0,1.1,0.1)):\n",
    "        self.attributes = attributes.copy()\n",
    "        self.bins = bins\n",
    "    \n",
    "    def generate_signature(self, h):\n",
    "        ''''\n",
    "        Convert numpy histogram in signature data structure necessary for the usage of OpenCV EMD\n",
    "        Create a matrix that each row is a frequency value obtained by the histogram algorithm and the bin value (position)\n",
    "        '''\n",
    "        return np.array([(n, self.bins[i]) for i,n in enumerate(h)]).astype(np.float32)\n",
    "    \n",
    "    def emd_pairwise(self, f_dist):\n",
    "        pairs = combinations(f_dist, 2)\n",
    "        emd_list = []\n",
    "        for pair in pairs:\n",
    "            sig1 = self.generate_signature(pair[0])\n",
    "            sig2 = self.generate_signature(pair[1])\n",
    "            emd_value, _, _ = cv2.EMD(sig1, sig2, cv2.DIST_L2)\n",
    "            emd_list.append(emd_value)\n",
    "            \n",
    "        return emd_list\n",
    "    \n",
    "    def generate_f_dist(self, f, partition):\n",
    "        samples = [f(row) for _,row in partition.iterrows()]\n",
    "        hist, _ = np.histogram(samples, bins=self.bins)\n",
    "        hist = hist / np.sum(hist)\n",
    "        return hist\n",
    "        \n",
    "    def worst_attribute(self,dataset,f,A):\n",
    "        worst_attr = ''\n",
    "        highest_emd = float('-inf')\n",
    "        splittable = None\n",
    "        \n",
    "        debug_n_datasets = 0\n",
    "        \n",
    "        for W in dataset:\n",
    "            debug_n_datasets += 1\n",
    "            for column, possible_values in A.items():\n",
    "                if type(possible_values) is not list:\n",
    "                    possible_values = np.arange(possible_values[0], possible_values[1]+1)\n",
    "                \n",
    "                partitions = self.split(W, column)\n",
    "                f_dist = [self.generate_f_dist(f, partition) for partition in partitions]\n",
    "                \n",
    "                # we need to make the pairwise EMD\n",
    "                emd_list = self.emd_pairwise(f_dist)\n",
    "\n",
    "                avg_emd = np.average(emd_list) if len(emd_list) > 0 else 0\n",
    "                if avg_emd > highest_emd:\n",
    "                    highest_emd = avg_emd\n",
    "                    worst_attr = column\n",
    "                    splittable = W\n",
    "        \n",
    "        if worst_attr is '' or highest_emd is float('-inf'):\n",
    "            print('Number of datasets {}'.format(debug_n_datasets))\n",
    "            raise ValueError(\"Worst Attribute not found\")\n",
    "            \n",
    "#         assert(worst_attr is not '' and highest_emd is not float('-inf'))\n",
    "        \n",
    "        return worst_attr, highest_emd, splittable\n",
    "        \n",
    "    def split(self,W,a):\n",
    "        if type(W) is list:\n",
    "            array = []\n",
    "            for w in W:\n",
    "                array += [df for _, df in w.groupby(a)]\n",
    "            return array\n",
    "                \n",
    "        return [df for _, df in W.groupby(a)]\n",
    "\n",
    "    def average_emd(self,W,f):\n",
    "        f_dists = []\n",
    "        emd_list = []\n",
    "        for partition in W:\n",
    "            f_dists.append(self.generate_f_dist(f, partition))\n",
    "\n",
    "        if len(f_dists) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        emd_list = self.emd_pairwise(f_dists)\n",
    "        return np.average(emd_list) if len(emd_list) > 0 else 0\n",
    "\n",
    "    def run(self,W,f,attr):\n",
    "        removal_list = []\n",
    "        avg_list = []\n",
    "        A = attr.copy()\n",
    "        \n",
    "        a, emd_val, splittable = self.worst_attribute([W],f,A)\n",
    "        \n",
    "        removal_list.append(a)\n",
    "        A.pop(a) # line 2 of the pseudo code\n",
    "        \n",
    "        current = self.split(splittable, a)\n",
    "        current_avg = self.average_emd(current, f)\n",
    "        avg_list.append(current_avg)\n",
    "\n",
    "        while len(A) > 0:\n",
    "            worst = self.worst_attribute(current,f,A)\n",
    "            a = worst[0]\n",
    "            A.pop(a)\n",
    "            children = self.split(current,a)\n",
    "            \n",
    "            children_avg = self.average_emd(children,f)\n",
    "            if current_avg >= children_avg:\n",
    "                break\n",
    "            else:\n",
    "                current = children\n",
    "                current_avg = children_avg\n",
    "                \n",
    "                avg_list.append(current_avg)\n",
    "                removal_list.append(a)\n",
    "\n",
    "        return current, np.mean(avg_list), removal_list, avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringFunction:\n",
    "    def __init__(self, alpha=0, b1_name='', b2_name=''):\n",
    "        self.a = alpha\n",
    "        self.b1_name = b1_name\n",
    "        self.b2_name = b2_name\n",
    "        \n",
    "    def f(self,row):\n",
    "        b1 = row[self.b1_name] / 100\n",
    "        b2 = row[self.b2_name] / 100\n",
    "        return (self.a*b1 + (1-self.a)*b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0,0.3,0.5,0.7,1.0]\n",
    "\n",
    "f1 = ScoringFunction(alpha=alpha[1], b1_name='language_test', b2_name='approval_rate').f\n",
    "f2 = ScoringFunction(alpha=alpha[3], b1_name='language_test', b2_name='approval_rate').f\n",
    "f3 = ScoringFunction(alpha=alpha[2], b1_name='language_test', b2_name='approval_rate').f\n",
    "f4 = ScoringFunction(alpha=alpha[4], b1_name='language_test', b2_name='approval_rate').f\n",
    "f5 = ScoringFunction(alpha=alpha[0], b1_name='language_test', b2_name='approval_rate').f\n",
    "\n",
    "f6 = lambda row: random.uniform(.8, 1) if row['gender'] == 'male' else random.uniform(0, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40ca3e683fd4ecb9caca4945d8ab63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r1 = []\n",
    "r2 = []\n",
    "r3 = []\n",
    "r4 = []\n",
    "r5 = []\n",
    "r6 = []\n",
    "for i in tqdm(range(10)):\n",
    "    balanced = BalancedAlgorithm(protected_attrs)\n",
    "    \n",
    "    result1 = balanced.run(small_dataset.copy(), f1, protected_attrs)\n",
    "    result2 = balanced.run(small_dataset.copy(), f2, protected_attrs)\n",
    "    result3 = balanced.run(small_dataset.copy(), f3, protected_attrs)\n",
    "    result4 = balanced.run(small_dataset.copy(), f4, protected_attrs)\n",
    "    result5 = balanced.run(small_dataset.copy(), f5, protected_attrs)\n",
    "    result6 = balanced.run(small_dataset.copy(), f6, protected_attrs)\n",
    "    \n",
    "    small_dataset = generate_dataset(500)\n",
    "    \n",
    "    r1.append(result1[1])\n",
    "    r2.append(result2[1])\n",
    "    r3.append(result3[1])\n",
    "    r4.append(result4[1])\n",
    "    r5.append(result5[1])\n",
    "    r6.append(result6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Average EMD = 0.16056981589040004\n",
      "F2 Average EMD = 0.15959194091186607\n",
      "F3 Average EMD = 0.15070597680094927\n",
      "F4 Average EMD = 0.21265280516487223\n",
      "F5 Average EMD = 0.2125389597122857\n",
      "F6 Average EMD = 0.8023243308067322\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Average EMD = {}\".format(np.average(r1)))\n",
    "print(\"F2 Average EMD = {}\".format(np.average(r2)))\n",
    "print(\"F3 Average EMD = {}\".format(np.average(r3)))\n",
    "print(\"F4 Average EMD = {}\".format(np.average(r4)))\n",
    "print(\"F5 Average EMD = {}\".format(np.average(r5)))\n",
    "print(\"F6 Average EMD = {}\".format(np.average(r6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
